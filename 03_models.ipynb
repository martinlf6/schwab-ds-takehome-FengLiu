{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zhPxvvKPTl_"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/martinlf6/schwab-ds-takehome-FengLiu/blob/main/03_models.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==3.6.0 --force-reinstall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sUsZ9oT5Wn5B",
        "outputId": "33ec4ba2-7089-4217-e941-35716fbfb04c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==3.6.0\n",
            "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting filelock (from datasets==3.6.0)\n",
            "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting numpy>=1.17 (from datasets==3.6.0)\n",
            "  Using cached numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting pyarrow>=15.0.0 (from datasets==3.6.0)\n",
            "  Using cached pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.6.0)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets==3.6.0)\n",
            "  Using cached pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "Collecting requests>=2.32.2 (from datasets==3.6.0)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tqdm>=4.66.3 (from datasets==3.6.0)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting xxhash (from datasets==3.6.0)\n",
            "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.6.0)\n",
            "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting huggingface-hub>=0.24.0 (from datasets==3.6.0)\n",
            "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting packaging (from datasets==3.6.0)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from datasets==3.6.0)\n",
            "  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Using cached aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.24.0->datasets==3.6.0)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.24.0->datasets==3.6.0)\n",
            "  Using cached hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets==3.6.0)\n",
            "  Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets==3.6.0)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets==3.6.0)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets==3.6.0)\n",
            "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets==3.6.0)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets==3.6.0)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets==3.6.0)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Using cached multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
            "  Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets==3.6.0)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
            "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
            "Using cached numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Using cached pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Using cached aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
            "Using cached hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "Using cached multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
            "Installing collected packages: pytz, xxhash, urllib3, tzdata, typing-extensions, tqdm, six, pyyaml, pyarrow, propcache, packaging, numpy, multidict, idna, hf-xet, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, python-dateutil, multiprocess, aiosignal, pandas, huggingface-hub, aiohttp, datasets\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: xxhash\n",
            "    Found existing installation: xxhash 3.5.0\n",
            "    Uninstalling xxhash-3.5.0:\n",
            "      Successfully uninstalled xxhash-3.5.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 21.0.0\n",
            "    Uninstalling pyarrow-21.0.0:\n",
            "      Successfully uninstalled pyarrow-21.0.0\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.3.2\n",
            "    Uninstalling propcache-0.3.2:\n",
            "      Successfully uninstalled propcache-0.3.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.2\n",
            "    Uninstalling numpy-2.3.2:\n",
            "      Successfully uninstalled numpy-2.3.2\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.6.4\n",
            "    Uninstalling multidict-6.6.4:\n",
            "      Successfully uninstalled multidict-6.6.4\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.1.9\n",
            "    Uninstalling hf-xet-1.1.9:\n",
            "      Successfully uninstalled hf-xet-1.1.9\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.7.0\n",
            "    Uninstalling frozenlist-1.7.0:\n",
            "      Successfully uninstalled frozenlist-1.7.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.19.1\n",
            "    Uninstalling filelock-3.19.1:\n",
            "      Successfully uninstalled filelock-3.19.1\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.3\n",
            "    Uninstalling charset-normalizer-3.4.3:\n",
            "      Successfully uninstalled charset-normalizer-3.4.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.8.3\n",
            "    Uninstalling certifi-2025.8.3:\n",
            "      Successfully uninstalled certifi-2025.8.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.20.1\n",
            "    Uninstalling yarl-1.20.1:\n",
            "      Successfully uninstalled yarl-1.20.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.5\n",
            "    Uninstalling requests-2.32.5:\n",
            "      Successfully uninstalled requests-2.32.5\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.3.2\n",
            "    Uninstalling pandas-2.3.2:\n",
            "      Successfully uninstalled pandas-2.3.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.34.4\n",
            "    Uninstalling huggingface-hub-0.34.4:\n",
            "      Successfully uninstalled huggingface-hub-0.34.4\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.12.15\n",
            "    Uninstalling aiohttp-3.12.15:\n",
            "      Successfully uninstalled aiohttp-3.12.15\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 3.6.0\n",
            "    Uninstalling datasets-3.6.0:\n",
            "      Successfully uninstalled datasets-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 datasets-3.6.0 dill-0.3.8 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.3.0 hf-xet-1.1.9 huggingface-hub-0.34.4 idna-3.10 multidict-6.6.4 multiprocess-0.70.16 numpy-2.3.2 packaging-25.0 pandas-2.3.2 propcache-0.3.2 pyarrow-21.0.0 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 requests-2.32.5 six-1.17.0 tqdm-4.67.1 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 xxhash-3.5.0 yarl-1.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_multiprocess",
                  "aiohappyeyeballs",
                  "aiohttp",
                  "aiosignal",
                  "attr",
                  "certifi",
                  "datasets",
                  "dateutil",
                  "dill",
                  "filelock",
                  "frozenlist",
                  "fsspec",
                  "huggingface_hub",
                  "idna",
                  "multidict",
                  "multiprocess",
                  "numpy",
                  "packaging",
                  "pandas",
                  "propcache",
                  "pyarrow",
                  "pytz",
                  "requests",
                  "six",
                  "tqdm",
                  "urllib3",
                  "xxhash",
                  "yarl"
                ]
              },
              "id": "9744458c7a90476cbcfb684afc779fda"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load packages\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "Uk6nAGl-zg8h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "ds = load_dataset(\"financial_phrasebank\", \"sentences_allagree\") # 'sentences_allagree' means only sentences where all annotators agreed on the sentiment label are included in the loaded dataset. ds is now a DatasetDict object with splits like \"train\"\n",
        "df = ds[\"train\"].to_pandas().rename(columns={\"sentence\":\"text\",\"label\":\"y\"}) # Convert to Pandas dataframe. ds[\"train\"] selects the training split of the dataset\n",
        "label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"} # Create a mapping from numbers to labels\n",
        "df[\"label\"] = df[\"y\"].map(label_map) # Apply the mapping: replaces each numeric value in column y with its text label and creates a new column label with human-readable sentiment.\n",
        "df[\"len\"] = df[\"text\"].str.split().apply(len) # .split() splits each list in text column (sentence) on whitespace, another word, splits each sentence into words. apply(len) applies the built-in Python len() function to each list in text column (sentence) that gives the number of words in the sentence.\n"
      ],
      "metadata": {
        "id": "sj8tW7H4W3LA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b33444-74ad-408b-bb2d-d0780953bc1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "uXNsIEmzzAic",
        "outputId": "ce134dd0-ea24-43fc-df72-735f8d19e614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  y     label  len\n",
              "0     According to Gran , the company has no plans t...  1   neutral   25\n",
              "1     For the last quarter of 2010 , Componenta 's n...  2  positive   39\n",
              "2     In the third quarter of 2010 , net sales incre...  2  positive   29\n",
              "3     Operating profit rose to EUR 13.1 mn from EUR ...  2  positive   24\n",
              "4     Operating profit totalled EUR 21.1 mn , up fro...  2  positive   22\n",
              "...                                                 ... ..       ...  ...\n",
              "2259  Operating result for the 12-month period decre...  0  negative   27\n",
              "2260  HELSINKI Thomson Financial - Shares in Cargote...  0  negative   40\n",
              "2261  LONDON MarketWatch -- Share prices ended lower...  0  negative   26\n",
              "2262  Operating profit fell to EUR 35.4 mn from EUR ...  0  negative   23\n",
              "2263  Sales in Finland decreased by 10.5 % in Januar...  0  negative   19\n",
              "\n",
              "[2264 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-003e5ec6-4589-42a1-8e12-580ee9b92cf4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>y</th>\n",
              "      <th>label</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2259</th>\n",
              "      <td>Operating result for the 12-month period decre...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2260</th>\n",
              "      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262</th>\n",
              "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2263</th>\n",
              "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2264 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-003e5ec6-4589-42a1-8e12-580ee9b92cf4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-003e5ec6-4589-42a1-8e12-580ee9b92cf4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-003e5ec6-4589-42a1-8e12-580ee9b92cf4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install spaCy and python -m in order to load the spaCy transformer model, en_core_web_trf.\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_trf\n"
      ],
      "metadata": {
        "id": "cQdSkQ9rwUM5",
        "outputId": "a7643f5f-9ac9-4ab0-fa6a-4bc37bb9216a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.16.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.3.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-trf==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-curated-transformers<1.0.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from en-core-web-trf==3.8.0) (0.3.1)\n",
            "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.1.1)\n",
            "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.0.9)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.12/dist-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_trf\") # Load spaCy transformer model, en_core_web_trf, for aspect identification.\n"
      ],
      "metadata": {
        "id": "tXAzS0uWXCwH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an aspect-level dataset by transforming the sentence-level dataset using spaCy transformer model, en_core_web_trf.\n",
        "# Aspects: organizations, products (e.g., “ETF” (Exchange-Traded Fund), “credit card”, “mobile app”), key financial facets (“revenue”, “guidance”, “fees”).)\n",
        "\n",
        "# Define aspect extraction function\n",
        "def extract_aspects(text):\n",
        "    doc = nlp(text) # Runs the input text through spaCy’s NLP pipeline that will produce a Doc object with tokens, entities, and noun chunks.\n",
        "    aspects = [] # Initializes an empty list aspects to store extracted phrases.\n",
        "\n",
        "    # Named entities of interest\n",
        "    for ent in doc.ents: # Loops through recognized named entities (doc.ents).\n",
        "        if ent.label_ in {\"ORG\",\"PRODUCT\",\"WORK_OF_ART\"}:  # Keeps only those labeled as: \"ORG\", \"PRODUCT\" (products such as iPhone and Coca-Cola), and \"WORK_OF_ART\" (titles, works, etc.). Extend if needed.\n",
        "            aspects.append(ent.text) # Add the text to the aspects list.\n",
        "\n",
        "    # Extract financial noun chunks for financial facets\n",
        "    for nc in doc.noun_chunks: # Iterates over noun phrases (e.g., \"the quarterly revenue\", \"profit margin\")\n",
        "        head = nc.root.lemma_.lower() # Gets the root word’s lemma (base form)\n",
        "        if head in {\"revenue\",\"guidance\",\"dividend\",\"yield\",\"fees\",\"costs\",\"margin\",\"outlook\",\"results\",\"stock\",\"shares\"}: # If the root is one of the predefined financial terms (like \"revenue\", \"margin\", \"stock\", etc.), it’s considered an aspect.\n",
        "            aspects.append(nc.text) # Adds the entire chunk (nc.text) to aspects.\n",
        "\n",
        "    # Deduplicate results: returns a cleaned list of aspects.\n",
        "    aspects = list(dict.fromkeys(a.strip() for a in aspects if len(a.strip())>1)) # a.strip(): removes leading/trailing whitespace. len(a.strip())>1: ignores meaningless single-character tokens. dict.fromkeys(...): removes duplicates while preserving order.\n",
        "    return aspects\n",
        "\n",
        "df[\"aspects\"] = df[\"text\"].apply(extract_aspects) # Creates a new column aspects containing a list of extracted aspects for each sentence.\n",
        "df[\"num_aspects\"] = df[\"aspects\"].str.len() # Creates another column num_aspects with the number of aspects found.\n",
        "print(df[[\"text\",\"aspects\"]].head(10))\n",
        "\n",
        "# Transform the sentence-level dataset into an aspect-level dataset\n",
        "pairs = []\n",
        "for _, row in df.iterrows(): # Loops through the DataFrame df row by row.\n",
        "    s = row[\"text\"]; sent_label = row[\"label\"]; aspects = row[\"aspects\"] # s: the sentence text. sent_label: sentiment label (negative/neutral/positive). aspects: list of extracted aspects from the sentence.\n",
        "    if not aspects: # Skip sentences with no aspects (the sentence with no aspects is not useful for aspect-level analysis)\n",
        "        continue\n",
        "    if len(aspects) == 1:\n",
        "        pairs.append({\"sentence\": s, \"aspect\": aspects[0], \"label\": sent_label}) # If there’s exactly 1 aspect, create a dictionary with: \"sentence\" as full sentence text, \"aspect\" as the only aspect, and \"label\" as the sentence-level sentiment; and append it to pairs.\n",
        "    else:\n",
        "        # If there are multiple aspects in the same sentence: It duplicates the sentence into multiple rows, one for each aspect. Assigns the same sentence-level sentiment to each aspect (this is a simplification; in reality, some aspects might be positive while others are negative).\n",
        "        for a in aspects:\n",
        "            pairs.append({\"sentence\": s, \"aspect\": a, \"label\": sent_label})\n",
        "\n",
        "pairs_df = pd.DataFrame(pairs) # Convert to DataFrame, and now each row = one aspect, instead of one sentence.\n",
        "print(pairs_df.head())\n"
      ],
      "metadata": {
        "id": "sIJrv7WQznI8",
        "outputId": "534f067c-f1f9-469f-ae61-7bd280e0e1fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  According to Gran , the company has no plans t...   \n",
            "1  For the last quarter of 2010 , Componenta 's n...   \n",
            "2  In the third quarter of 2010 , net sales incre...   \n",
            "3  Operating profit rose to EUR 13.1 mn from EUR ...   \n",
            "4  Operating profit totalled EUR 21.1 mn , up fro...   \n",
            "5  Finnish Talentum reports its operating profit ...   \n",
            "6  Clothing retail chain Sepp+ñl+ñ 's sales incre...   \n",
            "7  Consolidated net sales increased 16 % to reach...   \n",
            "8  Foundries division reports its sales increased...   \n",
            "9  HELSINKI ( AFX ) - Shares closed higher , led ...   \n",
            "\n",
            "                             aspects  \n",
            "0                                 []  \n",
            "1                       [Componenta]  \n",
            "2                                 []  \n",
            "3                                 []  \n",
            "4                                 []  \n",
            "5                 [Finnish Talentum]  \n",
            "6                        [Sepp+ñl+ñ]  \n",
            "7                                 []  \n",
            "8          [Foundries, Machine Shop]  \n",
            "9  [AFX, Nokia, Sanyo, Nokian Tyres]  \n",
            "                                            sentence            aspect  \\\n",
            "0  For the last quarter of 2010 , Componenta 's n...        Componenta   \n",
            "1  Finnish Talentum reports its operating profit ...  Finnish Talentum   \n",
            "2  Clothing retail chain Sepp+ñl+ñ 's sales incre...         Sepp+ñl+ñ   \n",
            "3  Foundries division reports its sales increased...         Foundries   \n",
            "4  Foundries division reports its sales increased...      Machine Shop   \n",
            "\n",
            "      label  \n",
            "0  positive  \n",
            "1  positive  \n",
            "2  positive  \n",
            "3  positive  \n",
            "4  positive  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xQJqiZ8XQVyw",
        "outputId": "f535860e-76e5-4508-f9b5-3f5475e26f3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  y     label  len  \\\n",
              "0     According to Gran , the company has no plans t...  1   neutral   25   \n",
              "1     For the last quarter of 2010 , Componenta 's n...  2  positive   39   \n",
              "2     In the third quarter of 2010 , net sales incre...  2  positive   29   \n",
              "3     Operating profit rose to EUR 13.1 mn from EUR ...  2  positive   24   \n",
              "4     Operating profit totalled EUR 21.1 mn , up fro...  2  positive   22   \n",
              "...                                                 ... ..       ...  ...   \n",
              "2259  Operating result for the 12-month period decre...  0  negative   27   \n",
              "2260  HELSINKI Thomson Financial - Shares in Cargote...  0  negative   40   \n",
              "2261  LONDON MarketWatch -- Share prices ended lower...  0  negative   26   \n",
              "2262  Operating profit fell to EUR 35.4 mn from EUR ...  0  negative   23   \n",
              "2263  Sales in Finland decreased by 10.5 % in Januar...  0  negative   19   \n",
              "\n",
              "                                     aspects  num_aspects  \n",
              "0                                         []            0  \n",
              "1                               [Componenta]            1  \n",
              "2                                         []            0  \n",
              "3                                         []            0  \n",
              "4                                         []            0  \n",
              "...                                      ...          ...  \n",
              "2259                                      []            0  \n",
              "2260  [HELSINKI Thomson Financial, Cargotec]            2  \n",
              "2261              [MarketWatch, bank stocks]            2  \n",
              "2262                                      []            0  \n",
              "2263                                      []            0  \n",
              "\n",
              "[2264 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e6d29c1-86ba-4b7a-9af4-90d2227fd466\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>y</th>\n",
              "      <th>label</th>\n",
              "      <th>len</th>\n",
              "      <th>aspects</th>\n",
              "      <th>num_aspects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>25</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>39</td>\n",
              "      <td>[Componenta]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>29</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>24</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2259</th>\n",
              "      <td>Operating result for the 12-month period decre...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>27</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2260</th>\n",
              "      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>40</td>\n",
              "      <td>[HELSINKI Thomson Financial, Cargotec]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>26</td>\n",
              "      <td>[MarketWatch, bank stocks]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262</th>\n",
              "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>23</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2263</th>\n",
              "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>19</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2264 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e6d29c1-86ba-4b7a-9af4-90d2227fd466')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e6d29c1-86ba-4b7a-9af4-90d2227fd466 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e6d29c1-86ba-4b7a-9af4-90d2227fd466');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UwKOUmXwaZPp"
      },
      "outputs": [],
      "source": [
        "#######################################################################################\n",
        "# A) Sentence-Level Sentiment Classification (using sentence-level dataset)\n",
        "#######################################################################################\n",
        "# Split into train / test (80/20), stratified by label (balanced) ensuring that the proportion of each class (or label) is maintained in both subsets.\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"y\"])\n",
        "# Further split train into train / validation (90/10 of the 80%)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42, stratify=train_df[\"y\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "M8oRY4HzTbfd",
        "outputId": "e2af8c94-f5d3-45ca-dc91-31e081252422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  y     label  len  \\\n",
              "0     According to Gran , the company has no plans t...  1   neutral   25   \n",
              "1     For the last quarter of 2010 , Componenta 's n...  2  positive   39   \n",
              "2     In the third quarter of 2010 , net sales incre...  2  positive   29   \n",
              "3     Operating profit rose to EUR 13.1 mn from EUR ...  2  positive   24   \n",
              "4     Operating profit totalled EUR 21.1 mn , up fro...  2  positive   22   \n",
              "...                                                 ... ..       ...  ...   \n",
              "2259  Operating result for the 12-month period decre...  0  negative   27   \n",
              "2260  HELSINKI Thomson Financial - Shares in Cargote...  0  negative   40   \n",
              "2261  LONDON MarketWatch -- Share prices ended lower...  0  negative   26   \n",
              "2262  Operating profit fell to EUR 35.4 mn from EUR ...  0  negative   23   \n",
              "2263  Sales in Finland decreased by 10.5 % in Januar...  0  negative   19   \n",
              "\n",
              "                                     aspects  num_aspects  \n",
              "0                                         []            0  \n",
              "1                               [Componenta]            1  \n",
              "2                                         []            0  \n",
              "3                                         []            0  \n",
              "4                                         []            0  \n",
              "...                                      ...          ...  \n",
              "2259                                      []            0  \n",
              "2260  [HELSINKI Thomson Financial, Cargotec]            2  \n",
              "2261              [MarketWatch, bank stocks]            2  \n",
              "2262                                      []            0  \n",
              "2263                                      []            0  \n",
              "\n",
              "[2264 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46e28f6c-297d-4e7e-923e-00a4fe0c083a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>y</th>\n",
              "      <th>label</th>\n",
              "      <th>len</th>\n",
              "      <th>aspects</th>\n",
              "      <th>num_aspects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>25</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>39</td>\n",
              "      <td>[Componenta]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>29</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>24</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2259</th>\n",
              "      <td>Operating result for the 12-month period decre...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>27</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2260</th>\n",
              "      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>40</td>\n",
              "      <td>[HELSINKI Thomson Financial, Cargotec]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>26</td>\n",
              "      <td>[MarketWatch, bank stocks]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262</th>\n",
              "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>23</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2263</th>\n",
              "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>19</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2264 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46e28f6c-297d-4e7e-923e-00a4fe0c083a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46e28f6c-297d-4e7e-923e-00a4fe0c083a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46e28f6c-297d-4e7e-923e-00a4fe0c083a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Jp5-5tObh01N"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "MODEL_NAME = \"ProsusAI/finbert\"   # Loads FinBERT, a BERT model pre-trained on financial texts.\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) # Load the Tokenizer that will convert raw text (words/sentences) into numeric IDs that the model understands: input_ids (integer IDs) representing tokens and attention_mask (1s and 0s) showing which tokens are real vs. padding.\n",
        "\n",
        "# Tokenizes sentences into IDs the model can process.\n",
        "train_encodings = tokenizer(list(train_df[\"text\"]), truncation=True, padding=True, max_length=128) # Truncation and padding guarantee that every input has exactly 128 tokens.\n",
        "val_encodings   = tokenizer(list(val_df[\"text\"]), truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(list(test_df[\"text\"]), truncation=True, padding=True, max_length=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to TensorFlow Dataset with each element as a tuple: Inputs (dict(train_encodings)) and Labels (np.array(train_labels)).\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    np.array(train_df[\"y\"])\n",
        ")).shuffle(1000).batch(16) # Randomly shuffles the training dataset with a buffer size of 1000 samples to prevent the model from just memorizing the order of the data. Groups 16 samples per batch for training, which speeds up learning and makes gradients more stable.\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    np.array(val_df[\"y\"])\n",
        ")).batch(32) # Use a bigger batch size (32) since no backpropagate during validation with a lower memory usage.\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    np.array(test_df[\"y\"])\n",
        ")).batch(32)\n"
      ],
      "metadata": {
        "id": "TboU0OZlp6ZT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first element of the validation dataset\n",
        "for element in val_dataset.take(1):\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAhEI8zStOhT",
        "outputId": "941b2f15-f638-4f40-9c6f-645d230888f3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_ids': <tf.Tensor: shape=(32, 93), dtype=int32, numpy=\n",
            "array([[  101,  1006,  4748, ...,     0,     0,     0],\n",
            "       [  101,  2077, 17710, ...,     0,     0,     0],\n",
            "       [  101,  1996,  2512, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  1006,  4748, ...,     0,     0,     0],\n",
            "       [  101,  4748,  2361, ...,     0,     0,     0],\n",
            "       [  101,  1017,  2254, ...,  5958,  1012,   102]],\n",
            "      shape=(32, 93), dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(32, 93), dtype=int32, numpy=\n",
            "array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], shape=(32, 93), dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(32, 93), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 1, 1, 1]], shape=(32, 93), dtype=int32)>}, <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
            "array([2, 1, 1, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 0, 1,\n",
            "       1, 1, 2, 1, 1, 1, 1, 0, 0, 1])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads FinBERT as a TensorFlow model with a classification head (3 classes)\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(  # Output class predictions instead of just embeddings\n",
        "    MODEL_NAME,\n",
        "    num_labels=3, # Defines the number of output classes (3: negative, neutral, positive sentiment). The model will output a vector of length 3 for each input (e.g., [0.1, 0.7, 0.2] for probabilities).\n",
        "    id2label={0:\"negative\",1:\"neutral\",2:\"positive\"},\n",
        "    label2id={\"negative\":0,\"neutral\":1,\"positive\":2} # Map between numbers and human-friendly labels.\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaiwM-Q4bK0Z",
        "outputId": "200d5390-669f-4afb-853e-ada20522024c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check sentiment distribution and see whether need to address imbalance during model trainning.\n",
        "print(df[\"label\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7AxlusAWrpf",
        "outputId": "42123bdf-52a5-47ed-f69c-75cd523b7507"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "neutral     1391\n",
            "positive     570\n",
            "negative     303\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not run this cell with the imbalanced data\n",
        "# Compile the Model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5) # Optimizer: Adam with small learning rate (standard for BERT fine-tuning and too large a learning rate will destroy pre-trained weights). Fine-tuning usually uses values between 2e-5 and 5e-5.\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) # Loss: SparseCategoricalCrossentropy (used for multi-class classification when labels are integers, not one-hot (e.g., negative: [1, 0, 0], neutral: [0, 1, 0])).\n",
        "metrics = [\"accuracy\"]\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "# Train & evaluate\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=3) # The dataset will be passed through the model 3 times, and history stores a training log with metrics and loss over time.\n",
        "results = model.evaluate(test_dataset) # Run the trained model on the test dataset and returns a list: [loss, accuracy] (since the model is compiled with loss + accuracy).\n",
        "print(\"Test set results:\", results)"
      ],
      "metadata": {
        "id": "DLbEduBFWbKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the weighting approach to adjust the loss function to penalize misclassifications of minority classes more heavily to address imbalance.\n",
        "class_counts = np.bincount(train_df[\"y\"])\n",
        "total_samples = len(train_df[\"y\"])\n",
        "num_classes = len(class_counts)\n",
        "class_weights = {}\n",
        "for i, count in enumerate(class_counts): # Use inverse weighting\n",
        "   class_weights[i] = total_samples / (num_classes * count)\n",
        "\n",
        "# Define weighted loss\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def weighted_loss(y_true, y_pred):\n",
        "    # y_true: true labels (batch)\n",
        "    # y_pred: predicted logits (batch, num_classes)\n",
        "    y_true = tf.cast(y_true, tf.int32) # Ensures labels are integers\n",
        "    weights = tf.gather([class_weights[0], class_weights[1], class_weights[2]], y_true) # Lookup weights per class, and make mistakes on minority classes more costly.\n",
        "    unweighted_loss = loss_fn(y_true, y_pred) # Compute base loss\n",
        "    return tf.reduce_mean(unweighted_loss * weights) # Average batch loss and each sample’s loss is scaled by its class weight.\n",
        "\n",
        "# Compile the Model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "model.compile(optimizer=optimizer, loss=weighted_loss, metrics=[\"accuracy\"])\n",
        "\n",
        "# Train with validation\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=3)\n",
        "# Evaluate on test set\n",
        "results = model.evaluate(test_dataset)\n",
        "print(\"\\nTest set results:\", results)\n"
      ],
      "metadata": {
        "id": "EaUvWbKjZuro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################################\n",
        "# B) Aspect-Level Sentiment Classification (using the aspect-level dataset, pairs_df)\n",
        "#######################################################################################\n",
        "# Unlike general sentiment analysis (classify the whole sentence), here we analyze sentiment toward a specific aspect in the sentence.\n",
        "# Example:\n",
        "# Sentence: \"The food was great but the service was terrible.\"\n",
        "# Aspect: \"food\"     → label = positive\n",
        "# Aspect: \"service\"  → label = negative\n",
        "\n",
        "# Encode labels. Add a numeric label_id column (0: negative, 1: neutral, 2: positive) to the dataset.\n",
        "labels = [\"negative\",\"neutral\",\"positive\"]\n",
        "label2id = {l:i for i,l in enumerate(labels)}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "pairs_df[\"label_id\"] = pairs_df[\"label\"].map(label2id)\n"
      ],
      "metadata": {
        "id": "zqm7__8Bs4Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs_df"
      ],
      "metadata": {
        "id": "DDiUhTdq2-GH",
        "outputId": "136c54f6-dde1-482c-8287-148e328281b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  \\\n",
              "0     For the last quarter of 2010 , Componenta 's n...   \n",
              "1     Finnish Talentum reports its operating profit ...   \n",
              "2     Clothing retail chain Sepp+ñl+ñ 's sales incre...   \n",
              "3     Foundries division reports its sales increased...   \n",
              "4     Foundries division reports its sales increased...   \n",
              "...                                                 ...   \n",
              "2003  Operating profits in the half were  0.8 m , do...   \n",
              "2004  HELSINKI Thomson Financial - Shares in Cargote...   \n",
              "2005  HELSINKI Thomson Financial - Shares in Cargote...   \n",
              "2006  LONDON MarketWatch -- Share prices ended lower...   \n",
              "2007  LONDON MarketWatch -- Share prices ended lower...   \n",
              "\n",
              "                          aspect     label  label_id  \n",
              "0                     Componenta  positive         2  \n",
              "1               Finnish Talentum  positive         2  \n",
              "2                      Sepp+ñl+ñ  positive         2  \n",
              "3                      Foundries  positive         2  \n",
              "4                   Machine Shop  positive         2  \n",
              "...                          ...       ...       ...  \n",
              "2003                     Glisten  negative         0  \n",
              "2004  HELSINKI Thomson Financial  negative         0  \n",
              "2005                    Cargotec  negative         0  \n",
              "2006                 MarketWatch  negative         0  \n",
              "2007                 bank stocks  negative         0  \n",
              "\n",
              "[2008 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf725d5d-7b64-4f0f-a39c-47ffcf0392d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>aspect</th>\n",
              "      <th>label</th>\n",
              "      <th>label_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>Componenta</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Finnish Talentum reports its operating profit ...</td>\n",
              "      <td>Finnish Talentum</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Clothing retail chain Sepp+ñl+ñ 's sales incre...</td>\n",
              "      <td>Sepp+ñl+ñ</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Foundries division reports its sales increased...</td>\n",
              "      <td>Foundries</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Foundries division reports its sales increased...</td>\n",
              "      <td>Machine Shop</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>Operating profits in the half were  0.8 m , do...</td>\n",
              "      <td>Glisten</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004</th>\n",
              "      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n",
              "      <td>HELSINKI Thomson Financial</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005</th>\n",
              "      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n",
              "      <td>Cargotec</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006</th>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "      <td>MarketWatch</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007</th>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "      <td>bank stocks</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2008 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf725d5d-7b64-4f0f-a39c-47ffcf0392d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf725d5d-7b64-4f0f-a39c-47ffcf0392d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf725d5d-7b64-4f0f-a39c-47ffcf0392d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-64180429-8f94-4c8c-80ec-8bbcb57dac0b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64180429-8f94-4c8c-80ec-8bbcb57dac0b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-64180429-8f94-4c8c-80ec-8bbcb57dac0b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_66312fa0-17e3-4d07-84ee-f2d80f9676a6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pairs_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_66312fa0-17e3-4d07-84ee-f2d80f9676a6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pairs_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pairs_df",
              "summary": "{\n  \"name\": \"pairs_df\",\n  \"rows\": 2008,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1181,\n        \"samples\": [\n          \"The Network Test Business is part of Elektrobit 's Test and Automation Business Segment and employs 39 people in Finland and 22 people abroad , mainly in the US and Asia .\",\n          \"The enterprise value of Maritim Food AS has been determined as approximately EUR15m .\",\n          \"However , the brokers ' ratings on the stock differ .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspect\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1355,\n        \"samples\": [\n          \"Biohit\",\n          \"Kyro\",\n          \"Yara Suomi Ltd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"neutral\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/val split\n",
        "train_df, val_df = train_test_split(pairs_df, test_size=0.2, random_state=42, stratify=pairs_df[\"label_id\"])\n"
      ],
      "metadata": {
        "id": "vtOvPgxzWAVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize as (sentence, aspect) pairs and convert to TF Datasets\n",
        "train_enc = tokenizer(list(train_df[\"sentence\"]), list(train_df[\"aspect\"]), # Take two sequences: Sentence (context) and Aspect (the target entity/feature), and combine them.\n",
        "                      truncation=True, padding=True, max_length=160) # The output (e.g., train_enc) contains: input_ids (token IDs), attention_mask (1 for real tokens, 0 for padding), and token_type_ids (segment IDs (distinguish sentence vs aspect)).\n",
        "val_enc   = tokenizer(list(val_df[\"sentence\"]), list(val_df[\"aspect\"]),\n",
        "                      truncation=True, padding=True, max_length=160)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_enc),\n",
        "    np.array(train_df[\"label_id\"])\n",
        ")).shuffle(1000).batch(16)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_enc),\n",
        "    np.array(val_df[\"label_id\"])\n",
        ")).batch(32)\n"
      ],
      "metadata": {
        "id": "36khpTguWIjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first element of the validation dataset\n",
        "for element in val_dataset.take(1):\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXuptqBTdRyI",
        "outputId": "456e5c83-a26f-4bbf-83e4-09e31dc0fe2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_ids': <tf.Tensor: shape=(32, 154), dtype=int32, numpy=\n",
            "array([[  101,  1996,  1041, ...,     0,     0,     0],\n",
            "       [  101,  2041, 12184, ...,     0,     0,     0],\n",
            "       [  101, 19330,  5737, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  8223,  7442, ...,     0,     0,     0],\n",
            "       [  101,  1996,  4132, ...,     0,     0,     0],\n",
            "       [  101, 10920,  1011, ...,     0,     0,     0]],\n",
            "      shape=(32, 154), dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(32, 154), dtype=int32, numpy=\n",
            "array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], shape=(32, 154), dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(32, 154), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]], shape=(32, 154), dtype=int32)>}, <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
            "array([1, 2, 2, 1, 0, 2, 1, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 2, 0, 0, 2, 1,\n",
            "       1, 1, 2, 1, 2, 1, 1, 1, 1, 1])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check sentiment distribution and see whether need to address imbalance during model trainning.\n",
        "print(pairs_df[\"label\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rqjxyzrfgsw",
        "outputId": "a76aba27-56b7-440e-faf3-685b81ae03c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "neutral     1306\n",
            "positive     474\n",
            "negative     228\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the weighting approach to adjust the loss function to penalize misclassifications of minority classes more heavily to address imbalance.\n",
        "class_counts = np.bincount(train_df[\"label_id\"])\n",
        "total_samples = len(train_df[\"label_id\"])\n",
        "num_classes = len(class_counts)\n",
        "class_weights = {}\n",
        "for i, count in enumerate(class_counts): # Use inverse weighting\n",
        "   class_weights[i] = total_samples / (num_classes * count)\n",
        "\n",
        "# Aspect-based model (same backbone, new head)\n",
        "absa_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME, num_labels=3, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "# Define weighted loss\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")\n",
        "\n",
        "def weighted_loss(y_true, y_pred):\n",
        "    # y_true: true labels (batch)\n",
        "    # y_pred: predicted logits (batch, num_classes)\n",
        "    y_true = tf.cast(y_true, tf.int32) # Ensures labels are integers\n",
        "    weights = tf.gather([class_weights[0], class_weights[1], class_weights[2]], y_true) # Lookup weights per class, and make mistakes on minority classes more costly.\n",
        "    unweighted_loss = loss_fn(y_true, y_pred) # Compute base loss\n",
        "    return tf.reduce_mean(unweighted_loss * weights) # Average batch loss and each sample’s loss is scaled by its class weight.\n",
        "\n",
        "# Compile the Model\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=2e-5)\n",
        "absa_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=weighted_loss,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train & evaluate\n",
        "absa_model.fit(train_dataset, validation_data=val_dataset, epochs=3)\n",
        "absa_results = absa_model.evaluate(val_dataset)\n",
        "print(\"Aspect-based test set results:\", absa_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "Mi9wIzHhhYfd",
        "outputId": "a10f3694-bd4a-4d04-ffc8-e0a0c610b23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "101/101 [==============================] - 3410s 33s/step - loss: 0.2266 - accuracy: 0.9751 - val_loss: 0.0942 - val_accuracy: 0.9826\n",
            "Epoch 2/3\n",
            " 68/101 [===================>..........] - ETA: 16:56 - loss: 0.0429 - accuracy: 0.9972"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-829991756.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Train & evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mabsa_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mabsa_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabsa_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Aspect-based validation results:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsa_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_batch_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1802\u001b[0m                         ):\n\u001b[1;32m   1803\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "prev_pub_hash": "c975bc569b09cdc49e9f499aac075862b2ff7356b23b8f06b39f154846eb837e"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}